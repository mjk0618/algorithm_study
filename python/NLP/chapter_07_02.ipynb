{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인퍼런스 설정\n",
    "from ratsnlp.nlpbook.qa import QADeployArguments\n",
    "args = QADeployArguments(\n",
    "    pretrained_model_name=\"beomi/kcbert-base\",\n",
    "    downstream_model_dir=\"nlpbook/qa\",\n",
    "    max_seq_length=128,\n",
    "    max_query_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 로드\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 로드\n",
    "import torch\n",
    "fine_tuned_model_ckpt = torch.load(\n",
    "    args.downstream_model_checkpoint_path,\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 설정 로드\n",
    "from transformers import BertConfig\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 모델 초기화\n",
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering(pretrained_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 주입하기\n",
    "model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt[\"state_dict\"].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 모드\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인퍼런스\n",
    "def inference_fn(question, context):\n",
    "    if question and context:\n",
    "        # 질문을 토큰화하고 인덱싱, max_query_length보다 길면 자르기\n",
    "        truncated_query = tokenizer.encode(\n",
    "            question,\n",
    "            add_special_tokens=False,\n",
    "            truncation=True,\n",
    "            max_length=args.max_query_length\n",
    "       )\n",
    "       # 처리한 질문을 지문과 함께 토큰화하고 인덱싱, max_seq_length보다 길면 자르기\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text=truncated_query,\n",
    "            text_pair=context,\n",
    "            truncation=\"only_second\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=args.max_seq_length,\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**{k: torch.tensor([v]) for k, v in inputs.items()})\n",
    "            # 정답의 시작 위치와 관련된 로짓에서 가장 큰 값이 가리키는 토큰 위치를 알아내기\n",
    "            start_pred = outputs.start_logits.argmax(dim=-1).item()\n",
    "            # 정답의 끝 위치와 관련된 로짓에서 가장 큰 값이 가리키는 토큰 위치를 알아내기\n",
    "            end_pred = outputs.end_logits.argmax(dim=-1).item()\n",
    "            # 정답 시작부터 끝까지의 토큰 이어붙여 정답 만들기\n",
    "            pred_text = tokenizer.decode(inputs['input_ids'][start_pred:end_pred+1])\n",
    "    else:\n",
    "        pred_text = \"\"\n",
    "    return {\n",
    "        'question': question,\n",
    "        'context': context,\n",
    "        'answer': pred_text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 서비스\n",
    "from ratsnlp.nlpbook.qa import get_web_service_app\n",
    "app = get_web_service_app(inference_fn)\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf74378b3249af5359f07a9caa84b7a763805fcaf59590a4dc4a6d39ea6824f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
