{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 환경 설정\n",
    "\n",
    "import torch\n",
    "from ratsnlp.nlpbook.classification import ClassificationTrainArguments\n",
    "\n",
    "args = ClassificationTrainArguments(\n",
    "    pretrained_model_name=\"beomi/kcbert-base\",\n",
    "    downstream_task_name=\"pair-classification\",\n",
    "    downstream_corpus_name=\"klue-nli\",\n",
    "    downstream_model_dir=\"nlpbook/paircls\",\n",
    "    downstream_corpus_root_dir=\"content/Korpora\",\n",
    "    batch_size=32 if torch.cuda.is_available() else 4,\n",
    "    learning_rate=5e-5,\n",
    "    max_seq_length=64,\n",
    "    epochs=5,\n",
    "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
    "    seed=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set seed: 7\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 고정\n",
    "from ratsnlp import nlpbook\n",
    "nlpbook.set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='pair-classification', downstream_corpus_name='klue-nli', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='nlpbook/paircls', max_seq_length=64, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=5, batch_size=32, cpu_workers=16, fp16=False, tpu_cores=0)\n"
     ]
    }
   ],
   "source": [
    "# 로거 설정\n",
    "nlpbook.set_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ratsnlp:cache file(c:\\Users\\Kang MinJae\\Desktop\\Code\\algorithm_study\\python\\NLP\\content\\Korpora\\klue-nli\\klue_nli_train.json) exists, using cache!\n",
      "INFO:ratsnlp:cache file(c:\\Users\\Kang MinJae\\Desktop\\Code\\algorithm_study\\python\\NLP\\content\\Korpora\\klue-nli\\klue_nli_dev.json) exists, using cache!\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치 내려받기\n",
    "nlpbook.download_downstream_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 준비하기\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ratsnlp:Creating features from dataset file at content/Korpora\\klue-nli\n",
      "INFO:ratsnlp:loading train data... LOOKING AT content/Korpora\\klue-nli\\klue_nli_train.json\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp949' codec can't decode byte 0xec in position 69: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mratsnlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnlpbook\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m \u001b[39mimport\u001b[39;00m ClassificationDataset\n\u001b[0;32m      4\u001b[0m corpus \u001b[39m=\u001b[39m KlueNLICorpus()\n\u001b[1;32m----> 5\u001b[0m train_dataset \u001b[39m=\u001b[39m ClassificationDataset(\n\u001b[0;32m      6\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m      7\u001b[0m     corpus\u001b[39m=\u001b[39;49mcorpus,\n\u001b[0;32m      8\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m      9\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ratsnlp\\nlpbook\\classification\\corpus.py:146\u001b[0m, in \u001b[0;36mClassificationDataset.__init__\u001b[1;34m(self, args, tokenizer, corpus, mode, convert_examples_to_features_fn)\u001b[0m\n\u001b[0;32m    141\u001b[0m corpus_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    142\u001b[0m     args\u001b[39m.\u001b[39mdownstream_corpus_root_dir,\n\u001b[0;32m    143\u001b[0m     args\u001b[39m.\u001b[39mdownstream_corpus_name,\n\u001b[0;32m    144\u001b[0m )\n\u001b[0;32m    145\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreating features from dataset file at \u001b[39m\u001b[39m{\u001b[39;00mcorpus_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 146\u001b[0m examples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus\u001b[39m.\u001b[39;49mget_examples(corpus_path, mode)\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m convert_examples_to_features_fn(\n\u001b[0;32m    148\u001b[0m     examples,\n\u001b[0;32m    149\u001b[0m     tokenizer,\n\u001b[0;32m    150\u001b[0m     args,\n\u001b[0;32m    151\u001b[0m     label_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus\u001b[39m.\u001b[39mget_labels(),\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ratsnlp\\nlpbook\\paircls\\corpus.py:33\u001b[0m, in \u001b[0;36mKlueNLICorpus.get_examples\u001b[1;34m(self, data_path, mode)\u001b[0m\n\u001b[0;32m     31\u001b[0m     data_fpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m\"\u001b[39m\u001b[39mklue_nli_dev.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m data... LOOKING AT \u001b[39m\u001b[39m{\u001b[39;00mdata_fpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m examples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_examples(data_fpath)\n\u001b[0;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m examples\n",
      "File \u001b[1;32mc:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ratsnlp\\nlpbook\\paircls\\corpus.py:17\u001b[0m, in \u001b[0;36mKlueNLICorpus._create_examples\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_examples\u001b[39m(\u001b[39mself\u001b[39m, data_path):\n\u001b[0;32m     16\u001b[0m     examples \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 17\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(data_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m data:\n\u001b[0;32m     19\u001b[0m         example \u001b[39m=\u001b[39m ClassificationExample(\n\u001b[0;32m     20\u001b[0m             text_a\u001b[39m=\u001b[39mel[\u001b[39m\"\u001b[39m\u001b[39mpremise\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m             text_b\u001b[39m=\u001b[39mel[\u001b[39m\"\u001b[39m\u001b[39mhypothesis\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     22\u001b[0m             label\u001b[39m=\u001b[39mel[\u001b[39m\"\u001b[39m\u001b[39mgold_label\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     23\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Kang MinJae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m     \u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0xec in position 69: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# 학습 데이터셋 구축\n",
    "from ratsnlp.nlpbook.paircls import KlueNLICorpus\n",
    "from ratsnlp.nlpbook.classification import ClassificationDataset\n",
    "corpus = KlueNLICorpus()\n",
    "train_dataset = ClassificationDataset(\n",
    "    args=args,\n",
    "    corpus=corpus,\n",
    "    tokenizer=tokenizer,\n",
    "    mode=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이하 내용 Colab에서 실습\n",
    "# 나중에 local에서 실행하는 방법 찾아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf74378b3249af5359f07a9caa84b7a763805fcaf59590a4dc4a6d39ea6824f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
