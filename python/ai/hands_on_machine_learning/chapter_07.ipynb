{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __07. 앙상블 학습과 랜덤 포레스트__\n",
    "\n",
    "__7.1 투표 기반 분류기__\n",
    "\n",
    "큰 수의 법칙에 의해 각 분류기가 약한 학습기일지라도 충분히 많고 다양하다면 앙상블은 강한 학습기가 될 수 있다. <br>\n",
    "단, 이런 가정은 모든 분류기가 완벽하게 독립적이고 오차에 상관관계가 없어야 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_clf), (\"rf\", rnd_clf), (\"svc\", svm_clf)],\n",
    "    voting=\"hard\"\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "# 간접투표\n",
    "'''\n",
    "모든 분류기의 클래스의 확률을 예측할 수 있으면(predict_proba() 메서드가 있으면) 개별 분류기의 예측을\n",
    "평균 내어 확률이 가장 높은 클래스를 예측할 수 있다. 이를 간접 투표(soft voting)라고 한다.\n",
    "SVC는 probability 매개변수를 True로 지정해야 한다.\n",
    "'''\n",
    "svm_clf = SVC(probability=True)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_clf), (\"rf\", rnd_clf), (\"svc\", svm_clf)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.2 배깅과 페이스팅__\n",
    "\n",
    "- 배깅(bagging = bootstrap aggregating): 훈련 세트에서 중복을 허용하여 샘플링하는 방식 <br>\n",
    "- 페이스팅(pasting): 중복을 허용하지 않고 샘플링하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배깅\n",
    "# bootstrap=False로 하면 페이스팅\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oob(out-of-bag) 샘플을 이용한 평가\n",
    "# 배깅을 사용 시 어떤 것은 전혀 선택되지 않을 수 있는데 이를 oob라고 하고, 이 샘플들을 이용하여 평가하는 방법\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_  # 테스트 세트에서 약 90.1%의 정확도를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44382022, 0.55617978],\n",
       "       [0.33510638, 0.66489362],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06077348, 0.93922652],\n",
       "       [0.36548223, 0.63451777],\n",
       "       [0.04624277, 0.95375723],\n",
       "       [0.98802395, 0.01197605],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.70689655, 0.29310345],\n",
       "       [0.        , 1.        ],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.84408602, 0.15591398],\n",
       "       [0.96428571, 0.03571429],\n",
       "       [0.06315789, 0.93684211],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97560976, 0.02439024],\n",
       "       [0.93820225, 0.06179775],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.37195122, 0.62804878],\n",
       "       [0.9039548 , 0.0960452 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9494382 , 0.0505618 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16402116, 0.83597884],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36413043, 0.63586957],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.20670391, 0.79329609],\n",
       "       [0.40555556, 0.59444444],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03      , 0.97      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00526316, 0.99473684],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [0.90960452, 0.09039548],\n",
       "       [0.96666667, 0.03333333],\n",
       "       [0.97005988, 0.02994012],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02631579, 0.97368421],\n",
       "       [0.99492386, 0.00507614],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.81182796, 0.18817204],\n",
       "       [0.36158192, 0.63841808],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.69411765, 0.30588235],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89411765, 0.10588235],\n",
       "       [1.        , 0.        ],\n",
       "       [0.59162304, 0.40837696],\n",
       "       [0.13684211, 0.86315789],\n",
       "       [0.6122449 , 0.3877551 ],\n",
       "       [0.87113402, 0.12886598],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16042781, 0.83957219],\n",
       "       [0.88770053, 0.11229947],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03012048, 0.96987952],\n",
       "       [0.03278689, 0.96721311],\n",
       "       [0.24712644, 0.75287356],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8342246 , 0.1657754 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.27363184, 0.72636816],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96984925, 0.03015075],\n",
       "       [0.75294118, 0.24705882],\n",
       "       [0.00512821, 0.99487179],\n",
       "       [1.        , 0.        ],\n",
       "       [0.16759777, 0.83240223],\n",
       "       [0.64534884, 0.35465116],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04736842, 0.95263158],\n",
       "       [0.50867052, 0.49132948],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02762431, 0.97237569],\n",
       "       [1.        , 0.        ],\n",
       "       [0.22727273, 0.77272727],\n",
       "       [0.46376812, 0.53623188],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.03225806, 0.96774194],\n",
       "       [0.99393939, 0.00606061],\n",
       "       [0.29545455, 0.70454545],\n",
       "       [0.89175258, 0.10824742],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.75773196, 0.24226804],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97727273, 0.02272727],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95628415, 0.04371585],\n",
       "       [0.99019608, 0.00980392],\n",
       "       [0.0125    , 0.9875    ],\n",
       "       [0.23243243, 0.76756757],\n",
       "       [0.97109827, 0.02890173],\n",
       "       [0.29347826, 0.70652174],\n",
       "       [0.97752809, 0.02247191],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [0.75129534, 0.24870466],\n",
       "       [0.39306358, 0.60693642],\n",
       "       [0.39534884, 0.60465116],\n",
       "       [0.84615385, 0.15384615],\n",
       "       [0.94764398, 0.05235602],\n",
       "       [0.06315789, 0.93684211],\n",
       "       [0.80681818, 0.19318182],\n",
       "       [0.01149425, 0.98850575],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03296703, 0.96703297],\n",
       "       [0.98469388, 0.01530612],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01069519, 0.98930481],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94086022, 0.05913978],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99411765, 0.00588235],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39520958, 0.60479042],\n",
       "       [0.29569892, 0.70430108],\n",
       "       [0.00990099, 0.99009901],\n",
       "       [0.        , 1.        ],\n",
       "       [0.34782609, 0.65217391],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99425287, 0.00574713],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98369565, 0.01630435],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0049505 , 0.9950495 ],\n",
       "       [0.64117647, 0.35882353],\n",
       "       [0.92134831, 0.07865169],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98974359, 0.01025641],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08571429, 0.91428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0744186 , 0.9255814 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02994012, 0.97005988],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94797688, 0.05202312],\n",
       "       [0.72222222, 0.27777778],\n",
       "       [0.61202186, 0.38797814],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.16402116, 0.83597884],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94387755, 0.05612245],\n",
       "       [0.9744898 , 0.0255102 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48993289, 0.51006711],\n",
       "       [0.8255814 , 0.1744186 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99421965, 0.00578035],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96842105, 0.03157895],\n",
       "       [0.        , 1.        ],\n",
       "       [0.2254902 , 0.7745098 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.83529412, 0.16470588],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07784431, 0.92215569],\n",
       "       [0.99065421, 0.00934579],\n",
       "       [0.03296703, 0.96703297],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07608696, 0.92391304],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76331361, 0.23668639],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92857143, 0.07142857],\n",
       "       [0.98802395, 0.01197605],\n",
       "       [0.21354167, 0.78645833],\n",
       "       [0.14689266, 0.85310734],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22513089, 0.77486911],\n",
       "       [0.97206704, 0.02793296],\n",
       "       [0.01604278, 0.98395722],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99393939, 0.00606061],\n",
       "       [0.        , 1.        ],\n",
       "       [0.49230769, 0.50769231],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.10994764, 0.89005236],\n",
       "       [0.12777778, 0.87222222],\n",
       "       [0.98907104, 0.01092896],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [1.        , 0.        ],\n",
       "       [0.3556701 , 0.6443299 ],\n",
       "       [0.03431373, 0.96568627],\n",
       "       [0.54945055, 0.45054945],\n",
       "       [0.63101604, 0.36898396],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.60540541, 0.39459459],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.21468927, 0.78531073],\n",
       "       [0.80540541, 0.19459459],\n",
       "       [0.07602339, 0.92397661],\n",
       "       [0.99444444, 0.00555556],\n",
       "       [0.80346821, 0.19653179],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [0.07954545, 0.92045455],\n",
       "       [0.02336449, 0.97663551],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99447514, 0.00552486],\n",
       "       [0.90857143, 0.09142857],\n",
       "       [0.16374269, 0.83625731],\n",
       "       [0.94054054, 0.05945946],\n",
       "       [0.        , 1.        ],\n",
       "       [0.53296703, 0.46703297],\n",
       "       [0.07614213, 0.92385787],\n",
       "       [0.97860963, 0.02139037],\n",
       "       [0.84313725, 0.15686275],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95789474, 0.04210526],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.27586207, 0.72413793],\n",
       "       [0.98351648, 0.01648352],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74747475, 0.25252525],\n",
       "       [0.96103896, 0.03896104],\n",
       "       [1.        , 0.        ],\n",
       "       [0.67045455, 0.32954545],\n",
       "       [0.44692737, 0.55307263],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92352941, 0.07647059],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.84444444, 0.15555556],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76142132, 0.23857868],\n",
       "       [0.10857143, 0.89142857],\n",
       "       [0.52197802, 0.47802198],\n",
       "       [0.15591398, 0.84408602],\n",
       "       [0.        , 1.        ],\n",
       "       [0.89447236, 0.10552764],\n",
       "       [0.84020619, 0.15979381],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99479167, 0.00520833],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02234637, 0.97765363],\n",
       "       [0.96907216, 0.03092784],\n",
       "       [0.95698925, 0.04301075],\n",
       "       [1.        , 0.        ],\n",
       "       [0.48663102, 0.51336898],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98445596, 0.01554404],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9726776 , 0.0273224 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06486486, 0.93513514],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98963731, 0.01036269],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.13846154, 0.86153846],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.40909091, 0.59090909],\n",
       "       [0.10994764, 0.89005236],\n",
       "       [0.1959799 , 0.8040201 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98507463, 0.01492537],\n",
       "       [0.18918919, 0.81081081],\n",
       "       [0.98342541, 0.01657459],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94329897, 0.05670103],\n",
       "       [0.34391534, 0.65608466],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98901099, 0.01098901],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03468208, 0.96531792],\n",
       "       [0.98342541, 0.01657459],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02040816, 0.97959184],\n",
       "       [0.66129032, 0.33870968]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 샘플이 음/양 클래스에 속할 확률을 나타냄\n",
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.3 랜덤 패치와 랜덤 서브스페이스__ <br>\n",
    "<br>\n",
    "배깅은 샘플 뿐만 아니라 특성 샘플링도 지원한다. 이는 이미지등 고차원 데이터를 다룰 때 유용하다. <br>\n",
    "훈련 특성과 샘플을 모두 샘플링하는 것을 __랜덤 패치 방식__(random patches method)라고 하고, <br>\n",
    "훈련 샘플을 모두 사용하고 특성은 샘플링하는 것을 __랜덤 서브스페이스 방식__(random subspace method)라고 한다. <br>\n",
    "\n",
    "__7.4 랜덤 포레스트__ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaggingClassifier을 사용하여 RandomForestClassfier과 유사하게 만든 것\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16), n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09963481781076726\n",
      "sepal width (cm) 0.02498422243738783\n",
      "petal length (cm) 0.44027412044883085\n",
      "petal width (cm) 0.43510683930301414\n"
     ]
    }
   ],
   "source": [
    "# 특성 중요도\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST 이미지 특성 중요도\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rnd_clf.fit(mnist[\"data\"], mnist[\"target\"])\n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=mpl.cm.hot, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels([\"Not important\", \"very important\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.5 부스팅__<br>\n",
    "\n",
    "약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법을 말한다. <br>\n",
    "앞의 모델을 보완해나가면서 일련의 예측기를 학습시키는 것이다. <br>\n",
    "부스팅 방법으로는 에이다부스트(AdaBoost, adaptive boosting)와 그레이디언트 부스팅(gradient boosting)이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "에이다부스트는 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 방법으로 새로운 예측기가 <br>\n",
    "학습하기 어려운 샘플에 점점 더 맞춰지게 된다.\n",
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그레이디언트 부스팅\n",
    "'''\n",
    "에이다부스트처럼 앙상블에 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가한다.\n",
    "하지만 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 잔여 오차(residual error)에 새로운 예측기를 학습시킨다.\n",
    "'''\n",
    "\n",
    "# DecisionTreeRegressor를 잡음이 섞인 2차 곡선 형태의 훈련 세트에 학습\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "# 첫 번째 예측기에서 생긴 잔여 오차에 두 번째 DecisionTreeRegressor를 훈련\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "# 같은 방법으로 세번째 회귀 모델 훈련\n",
    "y3 = y2- tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "# 세 개의 트리를 포함하는 앙상블 모델\n",
    "# 모든 트리의 예측을 더하면 새로운 샘플에 대한 예측이 된다.\n",
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그레이디언트 부스티드 회귀 트리(Gradient boosted regression tree, GBRT)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)\n",
    "y_pred = gbrt.predict(X_new)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=2, n_estimators=118)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=2, n_estimators=118)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=118)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 수를 찾는 방법\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기종료 구현\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.19678\n",
      "[1]\tvalidation_0-rmse:0.14325\n",
      "[2]\tvalidation_0-rmse:0.10835\n",
      "[3]\tvalidation_0-rmse:0.08482\n",
      "[4]\tvalidation_0-rmse:0.07044\n",
      "[5]\tvalidation_0-rmse:0.06255\n",
      "[6]\tvalidation_0-rmse:0.05927\n",
      "[7]\tvalidation_0-rmse:0.05698\n",
      "[8]\tvalidation_0-rmse:0.05519\n",
      "[9]\tvalidation_0-rmse:0.05513\n",
      "[10]\tvalidation_0-rmse:0.05474\n",
      "[11]\tvalidation_0-rmse:0.05463\n",
      "[12]\tvalidation_0-rmse:0.05427\n",
      "[13]\tvalidation_0-rmse:0.05376\n",
      "[14]\tvalidation_0-rmse:0.05377\n",
      "[15]\tvalidation_0-rmse:0.05363\n",
      "[16]\tvalidation_0-rmse:0.05358\n",
      "[17]\tvalidation_0-rmse:0.05387\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred = xgb_reg.predict(X_val)\n",
    "\n",
    "# 자동 조기 종료와 같은 기능도 제공\n",
    "xgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf74378b3249af5359f07a9caa84b7a763805fcaf59590a4dc4a6d39ea6824f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
