{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)  # 입력 이미지 차원\n",
    "\n",
    "z_dim = 100  # 생성자의 입력으로 사용할 잡음 벡터의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DCGAN 생성자\n",
    "\n",
    "def build_generator(z_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 완전 연결 층을 사용해 입력을 7 * 7 * 256크기 텐서로 변경\n",
    "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))  \n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "    # 7 * 7 * 256에서 14 * 14 * 128 크기 텐서로 바꾸는 전치 합성곱 층\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    model.add(BatchNormalization())  # 배치 정규화\n",
    "\n",
    "    model.add(LeakyReLU(alpha=0.01))  # LeakyReLU 활성화 함수\n",
    "\n",
    "    # 14 * 14 * 128에서 14 * 14 * 64 크기 텐서로 바꾸는 전치 합성곱 층\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "\n",
    "    model.add(BatchNormalization())  # 배치 정규화\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))  # LeakyReLU 활성화 함수\n",
    "\n",
    "    # 14 * 14 * 64에서 28 * 28 * 1 크기 텐서로 바꾸는 전치 합성곱 층\n",
    "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    model.add(Activation('tanh'))  # tanh 활성화 함수를 사용하는 출력층\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DCGAN 판별자\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 28 * 28 * 1 텐서에서 14 * 14 *32 크기 텐서로 바꾸는 합성곱 층\n",
    "    model.add(\n",
    "        Conv2D(32,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))  # LeakyReLU 활성화 함수\n",
    "\n",
    "    # 14 * 14 * 32 텐서에서 7 * 7 * 64 크기 텐서로 바꾸는 합성곱 층\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               padding='same'))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))  # LeakyReLU 활성화 함수\n",
    "\n",
    "    # 7 * 7 * 64 텐서에서 3 * 3 * 128 크기 텐서로 바꾸는 합성곱 층\n",
    "    model.add(\n",
    "        Conv2D(128,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               padding='same'))\n",
    "\n",
    "    model.add(LeakyReLU(alpha=0.01))  # LeakyReLU 활성화 함수\n",
    "    \n",
    "    model.add(Flatten())  # 시그모이드 활성화 함수를 사용하는 출력층\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DCGAN 모델 생성과 컴파일\n",
    "def build_gan(generator, discriminator):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 생성자 + 판별자 모델 연결\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 모델 생성과 컴파일\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# 생성자 모델 생성\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "# 생성자 훈련시에는 판별자의 파라미터를 고정\n",
    "discriminator.trainable = False\n",
    "\n",
    "# 생성자를 훈련하기 위해 판별자를 고정한 GAN 모델을 생성하고 컴파일\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생성된 이미지를 출력\n",
    "def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    # 랜덤한 잡음 샘플링\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # 랜덤한 잡음에서 이미지 생성\n",
    "    gen_imgs = generator.predict(z, verbose=0)\n",
    "    \n",
    "    # 이미지 픽셀 값을 [0, 1]범위로 스케일 조정\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(4, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DCGAN 훈련 반복\n",
    "losses = []\n",
    "accuracies = []\n",
    "iteration_checkpoints = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "\n",
    "    # MNIST 데이터셋 로드\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # [0, 255] 흑백 픽셀 값을 [-1, 1]로 스케일 조정\n",
    "    X_train = X_train / 127.5 - 1.0\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # 진짜 이미지의 레이블 모두 1\n",
    "    real = np.ones((batch_size, 1))\n",
    "\n",
    "    # 가짜 이미지의 레이블 모두 0\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        # 진짜 이미지의 랜덤 배치 얻기\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # 가짜 이미지 배치 만들기\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(z, verbose=0)\n",
    "\n",
    "        # 판별자 훈련하기\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # 가짜 이미지 배치 만들기\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(z, verbose=0)\n",
    "\n",
    "        # 생성자 훈련하기\n",
    "        g_loss = gan.train_on_batch(z, real)\n",
    "\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            \n",
    "            # 훈련이 끝난 후에 그래프로 그리기위해 손실과 정확도를 저장하기\n",
    "            losses.append((d_loss, g_loss))\n",
    "            accuracies.append(100.0 * accuracy)\n",
    "            iteration_checkpoints.append(iteration + 1)\n",
    "\n",
    "            # 훈련 과정 출력\n",
    "            print(f'{iteration + 1} [D 손실: {d_loss}, 정확도: {100.0 * accuracy:.2f}%] [G 손실: {g_loss}]')\n",
    "\n",
    "            sample_images(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 실행\n",
    "iterations = 20000\n",
    "batch_size = 128\n",
    "sample_interval = 1000\n",
    "\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "\n",
    "# 판별자와 생성자의 훈련 그래프\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iteration_checkpoints, losses.T[0], label='Discriminator loss')\n",
    "plt.plot(iteration_checkpoints, losses.T[1], label='Generator loss')\n",
    "\n",
    "plt.xticks(iteration_checkpoints, rotation = 90)\n",
    "\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.array(accuracies)\n",
    "\n",
    "# 판별자의 정확도 그래프\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iteration_checkpoints, accuracies, label=\"Discriminator accuracy\")\n",
    "\n",
    "plt.xticks(iteration_checkpoints, rotation=90)\n",
    "plt.yticks(range(0, 100, 5))\n",
    "\n",
    "plt.title(\"Discriminator Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf74378b3249af5359f07a9caa84b7a763805fcaf59590a4dc4a6d39ea6824f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
